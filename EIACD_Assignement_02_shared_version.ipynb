{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmfcardeira/EIACD_Assignement_02/blob/main/EIACD_Assignement_02_shared_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Introduction\n",
        "---\n",
        "\n",
        "This notebook was developed by the following students, under the course **CC1023 – Elementos de Inteligência Artificial e Ciência de Dados 2024/2025**, of the Faculty of Sciences of the University of Porto (FCUP):\n",
        "\n",
        "**Matilde Amorim – 202208540**\n",
        "\n",
        "**Rita Saraiva – 202207331**\n",
        "\n",
        "**Rodrigo Cardeira – 202206533**\n",
        "\n",
        "This notebook explores a dataset related to student performance in secondary education.\n",
        "\n",
        "The goal is to analyze the factors influencing student academic success, thus allowing to build an intervention system that may flag individual students requiring extra attention and support.\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "The dataset used in this analysis contains information about student demographics, social and school-related factors, and academic performance. We will use various data analysis and machine learning techniques to gain insights from this data.\n",
        "\n",
        "**Key Questions:**\n",
        "\n",
        "*   What are the key factors that influence student performance (passing/failing)?\n",
        "*   Can we build a model to predict student success based on their characteristics?\n",
        "*   What insights can we gain from this analysis to potentially improve student outcomes?\n",
        "\n",
        "**Analysis Steps:**\n",
        "\n",
        "1.  Data Exploration (EDA): Understanding the data structure, content, and identifying patterns.\n",
        "2.  Data Preprocessing: Data Cleaning, data transformation and feature engineering\n",
        "3.  Data Modeling (Supervised Learning): Choosing and training suitable machine learning models.\n",
        "4.  Perfomance Evaluation: Assessing and optimizing model performance.\n",
        "5.  Interpretation of Results: Drawing conclusions and suggesting potential interventions.\n"
      ],
      "metadata": {
        "id": "CzrYESeJ-rxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#0. Setup and Library Imports\n",
        "\n",
        "---\n",
        "Initial setup and configurations, as well as the importing of necessary libraries."
      ],
      "metadata": {
        "id": "WgYz60XB1rNn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWmo4dE-o9rn",
        "outputId": "1529141a-728e-4b99-b169-58cc125f337d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup configured and libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure visualizations\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"Setup configured and libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 1. Data Exploration (EDA)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In this phase, we load the data and perform an initial analysis to understand its structure, content, and identify potential issues or characteristics relevant for preprocessing and modeling."
      ],
      "metadata": {
        "id": "R1Fri9PI1w04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Load the Dataset\n",
        "\n",
        "First, we load the `student-data.csv` file into a pandas DataFrame and display the first few rows to get an initial look at the data structure and content."
      ],
      "metadata": {
        "id": "s5exylrWq9lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = 'student-data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Dataset loaded.\")\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# Display the last 5 rows\n",
        "print(\"\\nLast 5 rows of the dataset:\")\n",
        "display(df.tail())"
      ],
      "metadata": {
        "id": "sSWa0Cvbq_Tk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "20318b57-1448-4c4b-ace5-3977733654ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/student-data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c61050dc90af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/student-data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/student-data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Initial Data Inspection\n",
        "\n",
        "Let's get some basic information about the dataset:\n",
        "*   Number of records (students) and features (columns).\n",
        "*   Column names.\n",
        "*   Data types of each column.\n",
        "*   Check for missing values.\n",
        "*   Check for duplicate rows."
      ],
      "metadata": {
        "id": "o00QlhZbrDpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the dataset (rows, columns)\n",
        "print(f\"Dataset Shape: {df.shape[0]} records and {df.shape[1]} features.\\n\")\n",
        "\n",
        "# Get column names\n",
        "print(\"Column Names:\")\n",
        "print(list(df.columns))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Get data types and non-null counts\n",
        "print(\"\\nData Types and Non-Null Counts:\")\n",
        "df.info()\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Check for missing values in each column\n",
        "print(\"\\nMissing Values per Column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "if missing_values.sum() == 0:\n",
        "    print(\"No missing values found.\")\n",
        "else:\n",
        "    print(f\"Total missing values: {missing_values.sum()}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicate_rows = df.duplicated().sum()\n",
        "print(f\"\\nNumber of Duplicate Rows: {duplicate_rows}\")\n",
        "if duplicate_rows > 0:\n",
        "    print(\"Consider removing duplicate rows in the preprocessing step.\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "DjS6y-cGrHA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from Initial Inspection:**\n",
        "\n",
        "*   The dataset contains 395 student records and 31 features.\n",
        "*   The features cover a range of demographic, social, school-related, and behavioral attributes.\n",
        "*   The target variable appears to be `passed` (yes/no).\n",
        "*   Most features are categorical (`object` type) or discrete numerical (`int64`). Many binary categorical features (like `schoolsup`, `famsup`, `paid`, etc.) are stored as strings.\n",
        "*   **Crucially, there are no missing values** in the dataset according to `df.info()` and `df.isnull().sum()`.\n",
        "*   **No duplicate rows** were found."
      ],
      "metadata": {
        "id": "_HAShi2ZrLuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Descriptive Statistics"
      ],
      "metadata": {
        "id": "MV7DmCPPwW4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not df.empty:\n",
        "    print(\"\\nDescriptive statistics for numerical features:\")\n",
        "    print(df.describe(include=[np.number])) # For numerical columns\n",
        "\n",
        "    print(\"\\nDescriptive statistics for categorical (object) features:\")\n",
        "    print(df.describe(include=['object'])) # For object columns"
      ],
      "metadata": {
        "id": "Sfqe0uduwYEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations from Descriptive Statistics:**\n",
        "\n",
        "**Numerical Features:**\n",
        "\n",
        "age: Ranges from 15 to 22, with a mean of about 16.7. Most students are between 16 and 18. The max age of 22 might be an outlier or represent students repeating years.\n",
        "\n",
        "Medu (Mother's education) & Fedu (Father's education): Range from 0 (none) to 4 (higher education).\n",
        "\n",
        "traveltime: 1 (<15 min) to 4 (>1 hour). Most students live relatively close (1 or 2).\n",
        "\n",
        "studytime: 1 (<2 hours) to 4 (>10 hours). Most study 2-5 hours (category 2).\n",
        "\n",
        "failures: Number of past class failures (0 to 3, n if 1<=n<3, else 4 - but data shows max 3). Most students have 0 failures.\n",
        "\n",
        "famrel (Quality of family relationships): 1 (very bad) to 5 (excellent). Generally good.\n",
        "\n",
        "freetime, goout, Dalc (Workday alcohol), Walc (Weekend alcohol): Graded 1 (very low) to 5 (very high).\n",
        "\n",
        "health: 1 (very bad) to 5 (very good).\n",
        "\n",
        "absences: Ranges from 0 to 75. The mean is around 5.7, but the standard deviation is high (8), and the max of 75 suggests potential outliers or data entry issues. We should investigate this further.\n",
        "\n",
        "**Categorical Features:**\n",
        "\n",
        "school: Two schools, 'GP' (Gabriel Pereira) is more frequent (349 students) than 'MS' (Mousinho da Silveira, 46 students). This is an imbalance.\n",
        "\n",
        "sex: More 'F' (female, 208) than 'M' (male, 187). Fairly balanced.\n",
        "\n",
        "address: Mostly 'U' (urban, 307) vs 'R' (rural, 88).\n",
        "\n",
        "famsize: Mostly 'GT3' (greater than 3, 281) vs 'LE3' (less or equal to 3, 114).\n",
        "\n",
        "Pstatus (Parent's cohabitation status): Mostly 'T' (together, 354) vs 'A' (apart, 41).\n",
        "\n",
        "Mjob, Fjob: 'other' is the most common category. 'teacher' and 'services' are also prominent. 'at_home' and 'health' are less common.\n",
        "\n",
        "reason: 'course' preference is the most common reason for choosing the school.\n",
        "\n",
        "guardian: 'mother' is the most common guardian.\n",
        "\n",
        "Binary categorical features (yes/no): schoolsup, famsup, paid, activities, nursery, higher, internet, romantic.\n",
        "\n",
        "higher (wants to take higher education): Most students ('yes', 375) want to.\n",
        "\n",
        "internet (internet access at home): Most students ('yes', 329) have it.\n",
        "\n",
        "passed (Target Variable): More students 'yes' (passed, 265) than 'no' (failed, 130). This shows a moderate class imbalance."
      ],
      "metadata": {
        "id": "ZeawOqPYwaNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Feature Analysis\n",
        "\n",
        "Now, let's analyze the features in more detail, separating them into numerical and categorical types.\n",
        "\n",
        "#### 1.3.1 Numerical Features\n",
        "\n",
        "We'll look at the statistical summary and distributions of numerical features."
      ],
      "metadata": {
        "id": "Za--dOFbrRXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numerical features (based on df.info())\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "print(\"Numerical Features:\")\n",
        "print(numerical_cols)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Get descriptive statistics for numerical features\n",
        "print(\"\\nDescriptive Statistics for Numerical Features:\")\n",
        "display(df[numerical_cols].describe())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Visualize distributions of numerical features\n",
        "print(\"\\nDistributions of Numerical Features:\")\n",
        "df[numerical_cols].hist(figsize=(15, 12), bins=15, layout=(-1, 4))\n",
        "plt.suptitle('Histograms of Numerical Features', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize potential outliers using boxplots\n",
        "print(\"\\nBoxplots of Numerical Features (to identify potential outliers):\")\n",
        "plt.figure(figsize=(18, 10))\n",
        "sns.boxplot(data=df[numerical_cols], orient='h')\n",
        "plt.title('Boxplots of Numerical Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dy-tDCcmrT3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Numerical Features:**\n",
        "\n",
        "*   **Age:** Ranges from 15 to 22. Most students are between 15 and 18. There are fewer older students (19+), which might be considered outliers or a specific subgroup.\n",
        "*   **Medu, Fedu (Mother's/Father's Education):** Ordinal scale (0-4). Most parents have some level of education (values > 0). Value 0 might indicate no education or missing information (though no NaNs were reported).\n",
        "*   **traveltime, studytime:** Ordinal scales (1-4). Most students have relatively short travel times and moderate study times (1-2 hours or 2-5 hours).\n",
        "*   **failures:** Number of past class failures (0-3). Most students have 0 failures. Value 3 likely represents '3 or more' failures. This feature is highly skewed.\n",
        "*   **famrel, freetime, goout, Dalc, Walc, health:** Ordinal scales (1-5). Distributions vary. `Dalc` (weekday alcohol) and `Walc` (weekend alcohol) are skewed towards lower consumption.\n",
        "*   **absences:** Number of school absences. Highly skewed to the right, ranging from 0 to 75. The value 75 seems like a significant outlier. Many students have 0 absences.\n",
        "*   **Outliers:** `absences` clearly shows potential outliers. `age` has a few values (20, 21, 22) that are less common. `failures` has a group at 3, which might represent an aggregation."
      ],
      "metadata": {
        "id": "a0G2IqgUrYtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.2 Categorical Features\n",
        "\n",
        "Let's examine the unique values and distributions for categorical features (including binary 'yes'/'no' features)."
      ],
      "metadata": {
        "id": "RpMEFognrhAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select categorical features (object type)\n",
        "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "print(\"Categorical Features:\")\n",
        "print(categorical_cols)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Analyze value counts for each categorical feature\n",
        "print(\"\\nValue Counts for Categorical Features:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(df[col].value_counts())\n",
        "    # Optional: Add percentage\n",
        "    # print(df[col].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Visualize distributions of categorical features\n",
        "print(\"\\nDistributions of Categorical Features:\")\n",
        "num_plots = len(categorical_cols)\n",
        "num_cols_grid = 4\n",
        "num_rows_grid = (num_plots + num_cols_grid - 1) // num_cols_grid # Calculate rows needed\n",
        "\n",
        "fig, axes = plt.subplots(num_rows_grid, num_cols_grid, figsize=(16, num_rows_grid * 4))\n",
        "axes = axes.flatten() # Flatten to easily iterate\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    sns.countplot(data=df, y=col, ax=axes[i], order=df[col].value_counts().index, hue=col, palette='viridis', legend=False)\n",
        "    axes[i].set_title(f'Distribution of {col}')\n",
        "    axes[i].set_xlabel('Count')\n",
        "    axes[i].set_ylabel('') # Remove y-label for clarity with y-ticks\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9lr0Dudtrj5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations for Categorical Features:**\n",
        "\n",
        "*   **school:** Two schools involved: 'GP' (Gabriel Pereira) and 'MS' (Mousinho da Silveira). 'GP' has significantly more students in this dataset.\n",
        "*   **sex:** Slightly more female ('F') students than male ('M').\n",
        "*   **address:** Most students live in Urban ('U') areas compared to Rural ('R').\n",
        "*   **famsize:** Family size is predominantly 'GT3' (Greater than 3) compared to 'LE3' (Less than or equal to 3).\n",
        "*   **Pstatus:** Parents' cohabitation status is mostly 'T' (Together) compared to 'A' (Apart).\n",
        "*   **Mjob, Fjob:** Diverse range of jobs. 'other' is the most common category for both parents. 'teacher' and 'services' are also frequent. 'at_home' is more common for mothers.\n",
        "*   **reason:** Most common reasons for choosing the school are 'course' preference, followed by 'home' proximity and 'reputation'.\n",
        "*   **guardian:** Most students have 'mother' as their guardian, followed by 'father', then 'other'.\n",
        "*   **schoolsup, famsup, paid, activities, nursery, higher, internet, romantic:** These are binary features ('yes'/'no').\n",
        "    *   `schoolsup`: Most students do *not* have extra educational support.\n",
        "    *   `famsup`: About half the students have family educational support.\n",
        "    *   `paid`: Most students do *not* take extra paid classes.\n",
        "    *   `activities`: About half the students participate in extra-curricular activities.\n",
        "    *   `nursery`: Most students attended nursery school.\n",
        "    *   `higher`: The vast majority of students want to pursue higher education. **This is highly imbalanced towards 'yes'.**\n",
        "    *   `internet`: Most students have internet access at home.\n",
        "    *   `romantic`: Most students are *not* in a romantic relationship.\n",
        "*   **passed (Target Variable):** More students passed ('yes') than failed ('no'). There is an imbalance, but it might not be severe enough to require complex handling initially. We need to quantify this."
      ],
      "metadata": {
        "id": "bbl6JdWCrkp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantify the target variable distribution\n",
        "print(\"\\nTarget Variable Distribution ('passed'):\")\n",
        "passed_counts = df['passed'].value_counts()\n",
        "passed_perc = df['passed'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(passed_counts)\n",
        "print(\"\\nPercentages:\")\n",
        "print(passed_perc)\n",
        "\n",
        "# Visualize target variable distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "# Updated countplot call:\n",
        "sns.countplot(data=df, x='passed', hue='passed', palette='Paired', legend=False)\n",
        "plt.title('Distribution of Target Variable (passed)')\n",
        "plt.xlabel('Passed Final Exam')\n",
        "plt.ylabel('Number of Students')\n",
        "\n",
        "# Add percentages to the plot (using iloc for position-based access)\n",
        "total = len(df)\n",
        "for i, count in enumerate(passed_counts):\n",
        "    plt.text(i, count + 5, f'{passed_perc.iloc[i]:.1f}% ({count})', ha='center')\n",
        "plt.ylim(0, max(passed_counts) * 1.15)  # Adjust y-limit for text\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4azC_DL7rm5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Variable Observation:**\n",
        "\n",
        "*   Approximately 67.1% of students passed ('yes'), while 32.9% failed ('no'). This confirms an imbalance where the 'passed' class is roughly twice the size of the 'failed' class."
      ],
      "metadata": {
        "id": "0QSgtC8eroeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Preliminary Relationship Analysis (Feature vs. Target)\n",
        "\n",
        "Let's briefly explore how some features relate to the target variable `passed`.\n",
        "\n",
        "#### 1.4.1 Numerical Features vs. `passed`"
      ],
      "metadata": {
        "id": "vGGDfEQOrsYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Numerical Features vs. Passed Status:\")\n",
        "\n",
        "# Select a few key numerical features to compare against 'passed'\n",
        "num_cols_to_compare = ['age', 'failures', 'absences', 'studytime', 'goout', 'Dalc', 'Walc']\n",
        "\n",
        "fig, axes = plt.subplots(len(num_cols_to_compare), 1, figsize=(8, len(num_cols_to_compare) * 4))\n",
        "if len(num_cols_to_compare) == 1: # Handle case of single plot\n",
        "    axes = [axes]\n",
        "\n",
        "for i, col in enumerate(num_cols_to_compare):\n",
        "    # Assign 'passed' to 'hue' and set legend=False\n",
        "    sns.boxplot(data=df, x='passed', y=col, ax=axes[i], hue='passed', palette='Paired', legend=False)\n",
        "    axes[i].set_title(f'{col} vs. Passed Status')\n",
        "    axes[i].set_xlabel('Passed Final Exam')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r2uoJzuDrwlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations (Numerical vs. Passed):**\n",
        "\n",
        "*   **failures:** Students who failed ('no') tend to have significantly more past failures than those who passed ('yes'). This looks like a strong predictor.\n",
        "*   **absences:** Students who failed seem to have slightly more absences on average, but the distributions have large overlaps and many outliers.\n",
        "*   **studytime:** Students who passed seem to report slightly higher study times, but the difference is not dramatic based on the boxplot medians/quartiles.\n",
        "*   **goout:** Students who failed tend to report going out more frequently.\n",
        "*   **Dalc, Walc:** Alcohol consumption appears slightly higher for students who failed, particularly weekend consumption (`Walc`), but median values are often the same.\n",
        "*   **age:** Older students seem slightly more likely to fail, but the distributions overlap considerably."
      ],
      "metadata": {
        "id": "H4vnw650rxtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4.2 Categorical Features vs. `passed`"
      ],
      "metadata": {
        "id": "QsPrIDeer0J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCategorical Features vs. Passed Status:\")\n",
        "\n",
        "# Select a few key categorical features to compare against 'passed'\n",
        "cat_cols_to_compare = ['sex', 'Medu', 'Fedu', 'schoolsup', 'higher', 'romantic', 'internet']\n",
        "\n",
        "# Use countplot with 'hue' for visualization\n",
        "fig, axes = plt.subplots(len(cat_cols_to_compare), 1, figsize=(10, len(cat_cols_to_compare) * 4.5))\n",
        "if len(cat_cols_to_compare) == 1: # Handle case of single plot\n",
        "    axes = [axes]\n",
        "\n",
        "for i, col in enumerate(cat_cols_to_compare):\n",
        "    order = sorted(df[col].unique()) if col in ['Medu', 'Fedu'] else None # Order education levels\n",
        "    sns.countplot(data=df, x=col, hue='passed', ax=axes[i], palette='Paired', order=order)\n",
        "    axes[i].set_title(f'{col} vs. Passed Status')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].legend(title='Passed')\n",
        "    # Add percentages within each category (optional, can make plots busy)\n",
        "    # for container in axes[i].containers:\n",
        "    #    axes[i].bar_label(container, fmt='%.0f')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Crosstab for 'higher' might be more revealing due to its imbalance\n",
        "print(\"\\nCrosstab: higher vs passed\")\n",
        "display(pd.crosstab(df['higher'], df['passed'], normalize='index') * 100) # Show percentage within 'higher' category"
      ],
      "metadata": {
        "id": "4XEA82e-r2pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations (Categorical vs. Passed):**\n",
        "\n",
        "*   **sex:** Pass rates seem roughly similar between males and females, perhaps slightly higher for females.\n",
        "*   **Medu, Fedu:** Higher parental education levels appear correlated with a higher pass rate. Students whose parents have higher education (e.g., levels 3 and 4) are more likely to pass.\n",
        "*   **schoolsup:** Students *with* school support ('yes') have a noticeably lower pass rate than those without. This is counter-intuitive and needs investigation. Perhaps students receiving support are already those struggling academically?\n",
        "*   **higher:** Almost all students who want to go on to higher education ('yes') passed. Conversely, a large proportion of students *not* wanting to go to higher education ('no') failed. This seems like a very strong indicator.\n",
        "*   **romantic:** Students in a romantic relationship ('yes') appear to have a lower pass rate.\n",
        "*   **internet:** Having internet access seems slightly associated with a higher pass rate."
      ],
      "metadata": {
        "id": "PSfsUBK2r5FP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Summary of Data Exploration Findings & Potential Issues\n",
        "\n",
        "1.  **Dataset Size:** 395 records, 31 features. Manageable size.\n",
        "2.  **Target Variable:** `passed` (Categorical: 'yes'/'no').\n",
        "3.  **Class Imbalance:** The target variable is imbalanced (approx. 67% 'yes', 33% 'no'). This should be considered during modeling and evaluation (e.g., using appropriate metrics like F1-score, Precision, Recall, AUC, and potentially resampling techniques).\n",
        "4.  **Feature Types:** Mix of numerical (mostly discrete/ordinal) and categorical (many binary 'yes'/'no'). Categorical features will need encoding (e.g., One-Hot, Ordinal) for most ML models. Binary 'yes'/'no' features can be easily mapped to 1/0.\n",
        "5.  **Missing Values:** None found.\n",
        "6.  **Duplicates:** None found.\n",
        "7.  **Outliers:** `absences` has significant potential outliers. `age` has a few older students. Decisions on handling these (e.g., clipping, removal, transformation) should be made during preprocessing.\n",
        "8.  **Potential Predictors:** Features like `failures`, `higher`, `Medu`, `Fedu`, `schoolsup`, `goout`, `studytime`, and `romantic` showed noticeable associations with the `passed` status in the preliminary analysis and warrant further investigation.\n",
        "9.  **Highly Skewed Features:** `failures` and `absences` are highly skewed. Transformations (e.g., log transform for `absences` if appropriate) might be considered.\n",
        "\n",
        "10. **Underrepresented Categories:**\n",
        "    `school`: 'MS' has significantly fewer students than 'GP'.\n",
        "     Some job categories (`Mjob`, `Fjob`) and `guardian`='other' have low frequencies.\n",
        "     This could impact model performance or generalization, especially if these rare categories are important predictors.\n",
        "11. **Potential Irrelevant Features (Hypothesis - to be confirmed with further analysis/modeling):**\n",
        "       It's hard to definitively say at this stage. Domain knowledge suggests most of these features could be relevant to student performance. Feature selection techniques will be important later.\n",
        "       For example, `nursery` (attended nursery school) might have less impact on secondary school performance compared to more recent factors.\n",
        "12. **Data Scale:**\n",
        "      Numerical features are on different scales (e.g., `age` vs `absences`).\n",
        "       Scaling/Normalization will be necessary for algorithms sensitive to feature magnitudes (e.g., KNN, SVM, Neural Networks)\n",
        "10. **Feature Redundancy:** Although not explicitly checked with a correlation matrix for numerical features (omitted here for brevity, but recommended), potential redundancy might exist (e.g., `Medu` and `Fedu`, `Dalc` and `Walc`). `Dalc` and `Walc` could potentially be combined into a total alcohol consumption feature.\n",
        "11. **Counter-intuitive Relationships:** The relationship between `schoolsup` and `passed` (students *with* support having lower pass rates) is unexpected and suggests that this feature might be capturing students who are already at risk.\n",
        "\n",
        "**Next Steps (Data Cleaning and Preprocessing):**\n",
        "\n",
        "*   Encode categorical features (binary and multi-class).\n",
        "*   Address outliers (especially in `absences`).\n",
        "*   Consider feature scaling for numerical features if using distance-based algorithms (like KNN) or models sensitive to scale (like some Neural Networks, SVMs).\n",
        "*   Handle class imbalance if initial model performance is poor for the minority class ('no').\n",
        "*   Potentially perform feature engineering (e.g., combining alcohol consumption) or feature selection.\n",
        "*   Further investigate correlations between features."
      ],
      "metadata": {
        "id": "-m5Bb6eHr-jf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#2. Data Cleaning and Preprocessing\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Based on the EDA, we will now clean and prepare the data for machine learning modeling. We will work on a copy."
      ],
      "metadata": {
        "id": "QbaZF96L3paU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create a Copy"
      ],
      "metadata": {
        "id": "-xTFyTXw4COZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Work on a copy to preserve the original data 'df'\n",
        "df_processed = df.copy()\n",
        "\n",
        "print(\"Working on a copy of the original DataFrame.\")\n",
        "print(f\"Initial shape for processing: {df_processed.shape}\")"
      ],
      "metadata": {
        "id": "tJWAEf1g4EGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Feature Cleaning and Preprocessing\n",
        "\n",
        "In this section, we will clean and transform the features identified during EDA to make them suitable for machine learning models. This includes encoding categorical variables, handling outliers and skewness in numerical variables, and potentially engineering new features."
      ],
      "metadata": {
        "id": "6mdycNy2a4Bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Handling Categorical Features\n",
        "\n",
        "Most machine learning algorithms require numerical input. Therefore, we need to convert categorical features into a numerical format. We'll handle binary features by mapping them to 0/1 and multi-category nominal features using One-Hot Encoding."
      ],
      "metadata": {
        "id": "4KzJW2xJIwbv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2d8pNeUsNUzH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
